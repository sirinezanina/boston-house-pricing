{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da795034",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.11.11)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\zanin\\Documents\\studies\\uni-studies\\DNI\\DNI_I\\S2\\Traitement de donnees\\boston-house-pricing\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfedadd",
   "metadata": {},
   "source": [
    "## Let's load the Boston House Pricing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3090c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./HousingData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6287d",
   "metadata": {},
   "source": [
    "CRIM - per capita crime rate by town\n",
    "\n",
    "ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "INDUS - proportion of non-retail business acres per town.\n",
    "\n",
    "CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "\n",
    "NOX - nitric oxides concentration (parts per 10 million)\n",
    "\n",
    "RM - average number of rooms per dwelling\n",
    "\n",
    "AGE - proportion of owner-occupied units built prior to 1940\n",
    "\n",
    "DIS - weighted distances to five Boston employment centres\n",
    "\n",
    "RAD - index of accessibility to radial highways\n",
    "\n",
    "TAX - full-value property-tax rate per $10,000\n",
    "\n",
    "PTRATIO - pupil-teacher ratio by town\n",
    "\n",
    "B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "\n",
    "LSTAT - % lower status of the population\n",
    "\n",
    "MEDV - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf880acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's check the description of the dataset\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc3682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[\"CRIM\",\"ZN\",\"INDUS\",\"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\"RAD\",\"TAX\",\"PTRATIO\",\"B\",\"LSTAT\",\"MEDV\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2920eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MEDV']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4abcef0",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe000b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X (features) and y (target)\n",
    "X = df.drop(columns='MEDV')  \n",
    "y = df['MEDV']               \n",
    "\n",
    "# Get feature names\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "\n",
    "dataset = pd.DataFrame(X.values, columns=feature_names)\n",
    "\n",
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994a2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Price']=y.values\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06499919",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79915075",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarizing the dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a56d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check the missing values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b998fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numerical columns with mean\n",
    "for col in ['CRIM', 'ZN','INDUS', 'AGE', 'LSTAT']:\n",
    "    dataset[col] = dataset[col].fillna(dataset[col].mean())\n",
    "\n",
    "# Fill categorical column with mode\n",
    "dataset['CHAS'] = dataset['CHAS'].fillna(dataset['CHAS'].mode()[0])\n",
    "\n",
    "# Now check again:\n",
    "print(dataset.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "## Correlation\n",
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51d2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset['CRIM'], dataset['Price'])\n",
    "plt.xlabel('Crime Rate')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Crime Rate vs Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c60241",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset['RM'], dataset['Price'])\n",
    "plt.xlabel('Average Number of Rooms')\n",
    "plt.ylabel('Price') \n",
    "plt.title('Average Number of Rooms vs Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603cf51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.regplot(x='RM', y='Price', data=dataset, lowess=True, line_kws={'color': 'red', 'lw': 1})\n",
    "# we can see that the average number of rooms has a positive correlation with the price of the house.\n",
    "# The more rooms, the higher the price.\n",
    "# The regression line is a good fit for the data points.\n",
    "# The data points are not perfectly linear, but the trend is clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='LSTAT', y='Price', data=dataset, lowess=True, line_kws={'color': 'red', 'lw': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"CHAS\", y=\"Price\", data=dataset, lowess=True, line_kws={'color': 'red', 'lw': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=\"PTRATIO\", y=\"Price\", data=dataset, lowess=True, line_kws={'color': 'red', 'lw': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac0204",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Independant and Dependent features\n",
    "\n",
    "dataset\n",
    "# price is the dependent feature and the rest are independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also check the correlation between the features and the target variable (Price) using a heatmap.\n",
    "# The heatmap will show the correlation between all the features and the target variable.\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(dataset.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac236c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:, :-1]\n",
    "y=dataset.iloc[:, -1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c90a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018238c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test\n",
    "# We're not going to use the test set for training\n",
    "# We will use it to evaluate the model performance after training.\n",
    "# We will use the training set to train the model and the test set to evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09fedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Skewness: \", dataset.skew())\n",
    "print(\"Kurtosis: \", dataset.kurtosis())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8add42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in dataset.columns:\n",
    "    if col != 'Price':  # don't plot target\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.histplot(dataset[col], kde=True, bins=30)\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30af4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standaridze the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# in X_test_scaled we use transform instead of fit_transform because we don't want to fit the scaler again on the test set.\n",
    "# This is done to avoid data leakage from the test set into the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08340b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad3a016",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f21f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.fit(X_train_scaled, y_train)\n",
    "# The model is trained now.\n",
    "# We can check the coefficients of the model to see the importance of each feature.\n",
    "print(\"Coefficients: \", regression.coef_)\n",
    "# The coefficients represent the change in the target variable (Price) for a one unit change in the feature.\n",
    "# A positive coefficient means that the feature has a positive impact on the target variable (Price).\n",
    "# A negative coefficient means that the feature has a negative impact on the target variable (Price).\n",
    "# The larger the absolute value of the coefficient, the more important the feature is in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d6f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Intercept: \", regression.intercept_)\n",
    "# The intercept is the value of the target variable (Price) when all the features are 0.\n",
    "# In this case, it doesn't have much meaning because the features are standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4c37c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b87b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## on which parameter the model is trained on\n",
    "print(\"Parameters: \", regression.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction with Test Data\n",
    "reg_pred=regression.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd5f62",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8fdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot a scatter plot of the predicted values vs the actual values\n",
    "plt.scatter(y_test, reg_pred)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual Price vs Predicted Price')\n",
    "plt.show()\n",
    "# The plot is linear, which means that the model is a good fit for the data.\n",
    "# The points are close to the line, which means that the model is a good fit for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34caa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Residuals (Errors)\n",
    "residuals = y_test - reg_pred\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the residuals\n",
    "sns.displot(residuals, kde=True)\n",
    "plt.title('Residuals Distribution')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "# There are outliers in the residuals\n",
    "# We stil have a normal distribution of the residuals.\n",
    "# The residuals are normally distributed, which means that the model is a good fit for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420407d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scatter plot with respect to prediction and residuals\n",
    "plt.scatter(reg_pred, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "# They're scattered uniformly around 0, which means that the model is a good fit for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1abaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "print(\"Mean Absolute Error: \", mean_absolute_error(y_test, reg_pred))\n",
    "print(\"Mean Squared Error: \", mean_squared_error(y_test, reg_pred))\n",
    "print(\"Root Mean Squared Error: \", np.sqrt(mean_squared_error(y_test, reg_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 Score: \", r2_score(y_test, reg_pred))\n",
    "# The R2 score is 0.65, which means that the model explains 65% of the variance in the target variable (Price)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b3e223",
   "metadata": {},
   "source": [
    "## R square and adjusted R square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e092d48",
   "metadata": {},
   "source": [
    "$$\n",
    "R^2 = 1 - \\frac{SSR}{SST}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( R^2 \\) = Coefficient of determination\n",
    "- \\( SSR \\) = Sum of Squares of Residuals\n",
    "- \\( SST \\) = Total Sum of Squares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "score = r2_score(y_test, reg_pred)\n",
    "print(\"R2 Score: \", score)\n",
    "# The R2 score is 0.65, which means that the model explains 65% of the variance in the target variable (Price)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f3239",
   "metadata": {},
   "source": [
    "##### Adjusted R2 = 1 - [(1-R2)*(n-1)/(n-k-1)]\n",
    "Where: \n",
    "- R2: The R2 of the model\n",
    "- n: The number of observations\n",
    "- k: The number of predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d3c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display Adjusted R-squared \n",
    "1- (1-score)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2248924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# log-transform skewed features\n",
    "skewed_feats = ['CRIM','ZN','CHAS','B']\n",
    "log_tf = FunctionTransformer(np.log1p, validate=False)\n",
    "\n",
    "# column transformer\n",
    "preproc = ColumnTransformer([\n",
    "    ('log',     log_tf,        skewed_feats),\n",
    "    ('passthru','passthrough', [c for c in X_train.columns if c not in skewed_feats])\n",
    "])\n",
    "\n",
    "# full pipeline\n",
    "from tempfile import mkdtemp\n",
    "cachedir = mkdtemp()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pre',  preproc),\n",
    "    #('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)),\n",
    "    ('scale',StandardScaler()),\n",
    "    ('reg',  RandomForestRegressor(\n",
    "                  n_estimators=200,\n",
    "                  max_depth=5,\n",
    "                  min_samples_leaf=2,\n",
    "                  max_features='sqrt',\n",
    "                  random_state=0))\n",
    "], memory=cachedir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5151ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# R² on test\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Test  R²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# Cross-validated R² on train\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train,\n",
    "                            cv=5, scoring='r2')\n",
    "print(f\"CV R²: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab751c04",
   "metadata": {},
   "source": [
    "# New Data Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = X_test.iloc[[0]]  \n",
    "\n",
    "# predict\n",
    "prediction = pipeline.predict(new_data)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b269366f",
   "metadata": {},
   "source": [
    "## Pickling the Model file for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6533b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d665a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire pipeline, not just the regression model\n",
    "with open('regmodel.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ecd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('regmodel.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45528d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984efe89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
